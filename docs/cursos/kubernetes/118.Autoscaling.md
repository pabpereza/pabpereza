---
title: 'Autoscaling en Kubernetes - HPA, VPA y Cluster Autoscaler'
description: >-
  Domina el autoscaling en Kubernetes con HPA, VPA y Cluster Autoscaler. Aprende
  escalado horizontal y vertical autom√°tico para aplicaciones en producci√≥n.
keywords:
  - kubernetes autoscaling
  - HPA kubernetes
  - VPA kubernetes
  - cluster autoscaler
  - escalado autom√°tico
  - horizontal pod autoscaler
  - vertical pod autoscaler
sidebar_label: 18. Autoscaling
tags:
  - kubernetes
  - autoscaling
  - HPA
  - VPA
  - escalado
image: 'https://pabpereza.dev/img/banner_kubernetes.png'
slug: autoscaling_en_kubernetes_hpa_vpa_y_cluster_autoscaler
---

# Autoscaling en Kubernetes

El autoescalado es una de las caracter√≠sticas m√°s potentes de Kubernetes, permitiendo que tus aplicaciones se adapten din√°micamente a la carga de trabajo. En esta lecci√≥n nos centraremos en el **Horizontal Pod Autoscaler (HPA)**.

## Introducci√≥n

Imagina que tienes una tienda online. Durante la noche tienes pocos visitantes, pero en el Black Friday el tr√°fico se dispara. Si tienes una infraestructura est√°tica, o pagas de m√°s por recursos que no usas de noche, o tu sitio se cae en el pico de tr√°fico.

Aqu√≠ es donde entra el **Autoscaling**. Kubernetes puede aumentar o disminuir autom√°ticamente el n√∫mero de r√©plicas de tus Pods bas√°ndose en m√©tricas como el uso de CPU o memoria.

![HPA en Kubernetes](img/HPALifecycle.gif)

## Conceptos Fundamentales


### ¬øQu√© es el HPA (Horizontal Pod Autoscaler)?

El HPA escala el n√∫mero de Pods en un replication controller, deployment, replica set o stateful set bas√°ndose en la utilizaci√≥n de CPU observada (o, con soporte de m√©tricas personalizadas, en otras m√©tricas de la aplicaci√≥n).

*   **Escalado Horizontal**: A√±adir m√°s Pods (m√°quinas/contenedores) al pool.
*   **Escalado Vertical**: A√±adir m√°s recursos (CPU/RAM) a los Pods existentes (esto lo hace el VPA, que veremos en otra lecci√≥n junto con KEDA).
*   Cluster Autoscaler: Ajusta el n√∫mero de nodos en el cl√∫ster bas√°ndose en la demanda de recursos.
  
![Autoscaling en Kubernetes](img/AutoscalerComparison.gif)
  


### Requisitos Previos

Para que el HPA funcione, necesitas tener el **Metrics Server** instalado en tu cl√∫ster. Este componente se encarga de recolectar las m√©tricas de uso de recursos de los contenedores.

Puedes verificar si est√° funcionando con:
```bash
kubectl top nodes
kubectl top pods
```

## Ejemplo Pr√°ctico: HPA con la API Quotes

Para este ejemplo utilizaremos una aplicaci√≥n real: la **API de Citas C√©lebres** del repositorio [pabpereza/quotes](https://github.com/pabpereza/quotes). Esta API REST est√° construida con FastAPI y ya incluye probes de health check, lo que la hace perfecta para demostrar el autoescalado en Kubernetes.

> üì¶ Todos los manifiestos YAML est√°n disponibles en la carpeta [`deploy/`](https://github.com/pabpereza/quotes/tree/main/deploy) del repositorio.

### 1. Desplegar la aplicaci√≥n

Primero desplegamos la aplicaci√≥n con su Deployment y Service. Observa c√≥mo definimos **requests** de CPU y memoria, que son **esenciales** para que el HPA pueda calcular los porcentajes de uso.

Crea un archivo `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: quotes-deployment
  labels:
    app: quotes
spec:
  replicas: 3
  selector:
    matchLabels:
      app: quotes
  template:
    metadata:
      labels:
        app: quotes
    spec:
      containers:
        - name: quotes
          image: pabpereza/quotes
          ports:
            - containerPort: 80
          livenessProbe:
            httpGet:
              path: /probes/health
              port: 80
            initialDelaySeconds: 10
            periodSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /probes/ready
              port: 80
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 3
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              memory: "1024Mi"
---
apiVersion: v1
kind: Service
metadata:
  name: quotes-service
spec:
  selector:
    app: quotes
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
  type: ClusterIP
```

**Puntos clave del Deployment:**
- **`resources.requests`**: Define los recursos m√≠nimos que necesita cada Pod (100m CPU, 256Mi RAM). El HPA usa estos valores como referencia.
- **`livenessProbe` y `readinessProbe`**: La API expone endpoints en `/probes/health` y `/probes/ready` para que Kubernetes sepa cu√°ndo el Pod est√° sano y listo.
- **`replicas: 3`**: Iniciamos con 3 r√©plicas, pero el HPA ajustar√° este n√∫mero din√°micamente.

Aplica el manifiesto:

```bash
kubectl apply -f deployment.yaml
```

### 2. Crear el Horizontal Pod Autoscaler

Ahora configuramos el HPA. Este ejemplo es m√°s avanzado que el t√≠pico ejemplo de documentaci√≥n, ya que escala bas√°ndose en **CPU y memoria**, e incluye una configuraci√≥n de **comportamiento de desescalado**.

Crea un archivo `hpa.yaml`:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: quotes-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: quotes-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleDown:
      # Reducimos el periodo de cooldown de 5 a 3 minutos
      stabilizationWindowSeconds: 180
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
```

**Configuraci√≥n explicada:**
- **`minReplicas: 3`**: Mantiene siempre al menos 3 Pods para alta disponibilidad.
- **`maxReplicas: 10`**: L√≠mite m√°ximo para evitar un escalado descontrolado.
- **`metrics`**: Escala si la CPU **o** la memoria superan el 50% de los requests definidos.
- **`behavior.scaleDown`**: Configura el comportamiento al desescalar:
  - `stabilizationWindowSeconds: 180`: Espera 3 minutos (en lugar de 5) antes de reducir r√©plicas.
  - La pol√≠tica permite reducir hasta el 100% de las r√©plicas excedentes cada 15 segundos.

Aplica el HPA:
```bash
kubectl apply -f hpa.yaml
```

Verifica el estado del HPA:
```bash
kubectl get hpa quotes-hpa
```
*Deber√≠as ver algo como `TARGETS: 12%/50%, 8%/50%` (CPU y memoria).*

### 3. Generar Carga

El repositorio incluye un script de prueba de carga usando [k6](https://k6.io/). Este script simula usuarios reales que consultan citas, crean usuarios y autentican tokens.

Puedes ejecutar la prueba de carga con:

```bash
# Primero, exp√≥n el servicio (por ejemplo, con port-forward o Ingress)
kubectl port-forward svc/quotes-service 8080:8080 &

# Ejecuta k6 con el script de stress test
k6 run https://raw.githubusercontent.com/pabpereza/quotes/main/deploy/stress-test.js
```

O genera carga manualmente con un contenedor:

```bash
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://quotes-service:8080/quotes; done"
```

### 4. Observar el Escalado

Observa c√≥mo reacciona el HPA en tiempo real:

```bash
kubectl get hpa quotes-hpa -w
```

Ver√°s algo similar a:

```text
NAME         REFERENCE                      TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
quotes-hpa   Deployment/quotes-deployment   12%/50%, 8%/50%   3         10        3          1m
quotes-hpa   Deployment/quotes-deployment   85%/50%, 45%/50%  3         10        3          2m
quotes-hpa   Deployment/quotes-deployment   85%/50%, 45%/50%  3         10        6          3m
quotes-hpa   Deployment/quotes-deployment   42%/50%, 32%/50%  3         10        6          4m
```

Tambi√©n puedes ver el estado detallado:

```bash
kubectl describe hpa quotes-hpa
```

### 5. Detener la carga

Si detienes el generador de carga (Ctrl+C), ver√°s que despu√©s del periodo de estabilizaci√≥n (3 minutos en nuestra configuraci√≥n), el n√∫mero de r√©plicas volver√° a 3 (el m√≠nimo configurado).

## Conclusiones

El HPA es esencial para mantener la disponibilidad y el rendimiento de tus aplicaciones en Kubernetes sin intervenci√≥n manual, optimizando al mismo tiempo el uso de recursos y costes.

Recuerda:
1.  Necesitas **Metrics Server** instalado en tu cl√∫ster.
2.  Debes definir **Requests y Limits** en tus Pods para que el HPA pueda calcular los porcentajes correctamente.
3.  Configura **m√∫ltiples m√©tricas** (CPU y memoria) para un escalado m√°s inteligente.
4.  Ajusta el **comportamiento de desescalado** para evitar fluctuaciones innecesarias.
5.  Incluye **probes de health y readiness** para que Kubernetes gestione correctamente el tr√°fico durante el escalado.

## Recursos Adicionales

*   [Repositorio de ejemplo: pabpereza/quotes](https://github.com/pabpereza/quotes) - API completa con manifiestos de Kubernetes
*   [Carpeta deploy/ con todos los manifiestos](https://github.com/pabpereza/quotes/tree/main/deploy) - Deployment, HPA, Ingress y test de carga
*   [Documentaci√≥n oficial de Kubernetes sobre HPA](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
*   [Metrics Server en GitHub](https://github.com/kubernetes-sigs/metrics-server)
*   [k6 - Herramienta de pruebas de carga](https://k6.io/)


---
* Lista de v√≠deos en Youtube: [Curso Kubernetes](https://www.youtube.com/playlist?list=PLQhxXeq1oc2k9MFcKxqXy5GV4yy7wqSma)

[Volver al √≠ndice](README.md#√≠ndice)
